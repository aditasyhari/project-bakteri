{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unet Bakteri Segmentasi.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XadL5F7vKqo8",
        "outputId": "7ec2e0b5-781a-4079-cd37-ec686a37e3ae"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p686BbTkKgmN"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Activation, Lambda, GlobalAveragePooling2D, concatenate\n",
        "from tensorflow.keras.layers import UpSampling2D, Conv2D, Dropout, MaxPooling2D, Conv2DTranspose\n",
        "from tensorflow.keras.layers import Dense, Flatten, Input\n",
        "from tensorflow.keras.models import Model, Sequential, load_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import pickle\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHUTKMM8LPLp"
      },
      "source": [
        "IMG_HEIGHT = 160\n",
        "IMG_WIDTH = 160\n",
        "epochs = 20\n",
        "batch_size = 6\n",
        "ImgDir = \"/content/drive/MyDrive/Colab Notebooks/Bakteri/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVJxQQgRLXYZ",
        "outputId": "87852356-f2f9-4a1d-8fd4-1f7ca8fc5b08"
      },
      "source": [
        "features = os.listdir(f\"{ImgDir}image/\")\n",
        "labels = os.listdir(f\"{ImgDir}mask/\")\n",
        "\n",
        "print(len(features), len(labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "123 123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5Qm6737LfSk",
        "outputId": "dff21a52-94b9-4262-9b5c-9a243b47a1c5"
      },
      "source": [
        "X = features\n",
        "y = labels\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.15, random_state=1)\n",
        "\n",
        "print(len(X_train), len(X_val), len(X_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "86 31 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w298bV99LjXU"
      },
      "source": [
        "def keras_generator_train_val_test(batch_size, choice=\"train\"):\n",
        "    if choice == \"train\":\n",
        "        X = X_train\n",
        "        y = y_train\n",
        "    elif choice == \"val\":\n",
        "        X = X_val\n",
        "        y = y_val\n",
        "    elif choice == \"test\":\n",
        "        X = X_test\n",
        "        y = y_test\n",
        "    else:\n",
        "        print(\"Invalid Option\")\n",
        "        return False\n",
        "        \n",
        "    while True:\n",
        "        x_batch = []\n",
        "        y_batch = []\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            x_rand = random.choice(X)\n",
        "            y_rand = x_rand[:-4]+\".jpg\"\n",
        "            # print(y_rand)\n",
        "            x_path = f\"{ImgDir}image/{x_rand}\"\n",
        "            y_path = f\"{ImgDir}mask/{y_rand}\"\n",
        "\n",
        "            x = cv2.imread(x_path)\n",
        "            x = cv2.resize(x, (IMG_WIDTH, IMG_HEIGHT))\n",
        "            y = cv2.imread(y_path)\n",
        "            y = cv2.resize(y, (IMG_WIDTH, IMG_HEIGHT))\n",
        "\n",
        "            x = x / 255.0\n",
        "            y = y / 255.0\n",
        "            \n",
        "            x_batch.append(x)\n",
        "            y_batch.append(y)\n",
        "\n",
        "        x_batch = np.array(x_batch)\n",
        "\n",
        "        y_batch = {'seg': np.array(y_batch)}\n",
        "\n",
        "        yield x_batch, y_batch\n",
        "\n",
        "# for x, y in keras_generator_train_val_test(2, choice=\"train\"):\n",
        "#     break\n",
        "\n",
        "# print(x.shape, y['seg'].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej5Ih4MrfbYP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Fpp3EtSfbVE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIA6-PFMeLo2"
      },
      "source": [
        "# train_data = keras_generator_train_val_test(batch_size, choice=\"train\")\n",
        "# validation_data = keras_generator_train_val_test(batch_size, choice=\"val\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HqWmZUIek7f"
      },
      "source": [
        "# print(train_data)\n",
        "# print(validation_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaKxJoXDLsnB"
      },
      "source": [
        "# cv2_imshow(x[0] * 255.)\n",
        "# cv2_imshow(y['seg'][0] * 255.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFNjPAGuLtlL"
      },
      "source": [
        "def get_model():\n",
        "    in1 = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3 ))\n",
        "\n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(in1)\n",
        "    conv1 = Dropout(0.2)(conv1)\n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool1)\n",
        "    conv2 = Dropout(0.2)(conv2)\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool2)\n",
        "    conv3 = Dropout(0.2)(conv3)\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv3)\n",
        "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool3)\n",
        "    conv4 = Dropout(0.2)(conv4)\n",
        "    conv4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv4)\n",
        "\n",
        "    up1 = concatenate([UpSampling2D((2, 2))(conv4), conv3], axis=-1)\n",
        "    conv5 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(up1)\n",
        "    conv5 = Dropout(0.2)(conv5)\n",
        "    conv5 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv5)\n",
        "    \n",
        "    up2 = concatenate([UpSampling2D((2, 2))(conv5), conv2], axis=-1)\n",
        "    conv6 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(up2)\n",
        "    conv6 = Dropout(0.2)(conv6)\n",
        "    conv6 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv6)\n",
        "\n",
        "    up2 = concatenate([UpSampling2D((2, 2))(conv6), conv1], axis=-1)\n",
        "    conv7 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(up2)\n",
        "    conv7 = Dropout(0.2)(conv7)\n",
        "    conv7 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv7)\n",
        "    segmentation = Conv2D(3, (1, 1), activation='sigmoid', name='seg')(conv7)\n",
        "\n",
        "    model = Model(inputs=[in1], outputs=[segmentation])\n",
        "\n",
        "    losses = {'seg': 'binary_crossentropy'}\n",
        "\n",
        "    metrics = {'seg': ['acc']}\n",
        "    model.compile(optimizer=\"adam\", loss = losses, metrics=metrics)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ow2A1XwLLtiK"
      },
      "source": [
        "import datetime\n",
        "\n",
        "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
        "    def on_train_begin(self, epoch, logs={}):\n",
        "\n",
        "        res_dir = \"/content/drive/MyDrive/Colab Notebooks/Bakteri/result_white_background\"\n",
        "\n",
        "        try:\n",
        "            os.makedirs(res_dir)\n",
        "        except:\n",
        "            print(f\"{res_dir} directory already exist\")\n",
        "\n",
        "        print('Training: epoch {} begins at {}'.format(epoch, datetime.datetime.now().time()))\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        res_dir = \"/content/drive/MyDrive/Colab Notebooks/Bakteri/result_white_background/\"\n",
        "        print('Training: epoch {} ends at {}'.format(epoch, datetime.datetime.now().time()))\n",
        "        \n",
        "        for x_test, y_test in keras_generator_train_val_test(batch_size, choice=\"test\"):\n",
        "            break\n",
        "        p = np.reshape(x_test[0], (1, 160, 160, 3))\n",
        "        prediction = self.model.predict(p)\n",
        "\n",
        "        x_img = f\"{res_dir}{epoch}_X_input.jpg\"\n",
        "        y_img = f\"{res_dir}{epoch}_Y_truth.jpg\"\n",
        "        predicted_img = f\"{res_dir}{epoch}_Y_predicted.jpg\"\n",
        "\n",
        "        cv2.imwrite(x_img, x_test[0] * 255.)\n",
        "        cv2.imwrite(y_img, y_test['seg'][0] * 255.)\n",
        "        cv2.imwrite(predicted_img, prediction[0] * 255.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zaIEHEULtI9"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "model = get_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NgO2lmSL8dz"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWlxeOhqL8at",
        "outputId": "526d2050-27d3-498f-f3c9-43c5212eee5c"
      },
      "source": [
        "model_name = \"/content/drive/MyDrive/Colab Notebooks/model/\"+\"Unet_Bakteri_white_background.h5\"\n",
        "\n",
        "modelcheckpoint = ModelCheckpoint(model_name,\n",
        "                                  monitor='val_loss',\n",
        "                                  mode='auto',\n",
        "                                  verbose=1,\n",
        "                                  save_best_only=True)\n",
        "\n",
        "lr_callback = ReduceLROnPlateau(min_lr=0.001)\n",
        "\n",
        "callback_list = [modelcheckpoint, lr_callback, MyCustomCallback()]\n",
        "\n",
        "history = model.fit(\n",
        "    keras_generator_train_val_test(batch_size, choice=\"train\"),\n",
        "    validation_data = keras_generator_train_val_test(batch_size, choice=\"val\"),\n",
        "    validation_steps = 20,\n",
        "    steps_per_epoch= 20,\n",
        "    epochs=epochs,\n",
        "    verbose=1, \n",
        "    shuffle=True,\n",
        "    callbacks = callback_list,\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Bakteri/result_white_background directory already exist\n",
            "Training: epoch {} begins at 13:31:04.753578\n",
            "Epoch 1/20\n",
            "20/20 [==============================] - 98s 5s/step - loss: 0.6159 - acc: 0.3855 - val_loss: 0.5043 - val_acc: 0.0601\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.50426, saving model to /content/drive/MyDrive/Colab Notebooks/model/Unet_Bakteri_white_background.h5\n",
            "Training: epoch 0 ends at 13:32:43.307531\n",
            "Epoch 2/20\n",
            "20/20 [==============================] - 97s 5s/step - loss: 0.4739 - acc: 0.2658 - val_loss: 0.3831 - val_acc: 0.2421\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.50426 to 0.38309, saving model to /content/drive/MyDrive/Colab Notebooks/model/Unet_Bakteri_white_background.h5\n",
            "Training: epoch 1 ends at 13:34:23.288733\n",
            "Epoch 3/20\n",
            "20/20 [==============================] - 97s 5s/step - loss: 0.3790 - acc: 0.3000 - val_loss: 0.3175 - val_acc: 0.3863\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.38309 to 0.31747, saving model to /content/drive/MyDrive/Colab Notebooks/model/Unet_Bakteri_white_background.h5\n",
            "Training: epoch 2 ends at 13:36:02.312406\n",
            "Epoch 4/20\n",
            "20/20 [==============================] - 96s 5s/step - loss: 0.3130 - acc: 0.3026 - val_loss: 0.2287 - val_acc: 0.1593\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.31747 to 0.22866, saving model to /content/drive/MyDrive/Colab Notebooks/model/Unet_Bakteri_white_background.h5\n",
            "Training: epoch 3 ends at 13:37:39.595040\n",
            "Epoch 5/20\n",
            "20/20 [==============================] - 97s 5s/step - loss: 0.2674 - acc: 0.2918 - val_loss: 0.1703 - val_acc: 0.1447\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.22866 to 0.17029, saving model to /content/drive/MyDrive/Colab Notebooks/model/Unet_Bakteri_white_background.h5\n",
            "Training: epoch 4 ends at 13:39:17.585177\n",
            "Epoch 6/20\n",
            "20/20 [==============================] - 96s 5s/step - loss: 0.2269 - acc: 0.3511 - val_loss: 0.1308 - val_acc: 0.2532\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.17029 to 0.13083, saving model to /content/drive/MyDrive/Colab Notebooks/model/Unet_Bakteri_white_background.h5\n",
            "Training: epoch 5 ends at 13:40:55.241064\n",
            "Epoch 7/20\n",
            "20/20 [==============================] - 95s 5s/step - loss: 0.1772 - acc: 0.3449 - val_loss: 0.1085 - val_acc: 0.4812\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.13083 to 0.10850, saving model to /content/drive/MyDrive/Colab Notebooks/model/Unet_Bakteri_white_background.h5\n",
            "Training: epoch 6 ends at 13:42:31.573845\n",
            "Epoch 8/20\n",
            "20/20 [==============================] - 95s 5s/step - loss: 0.1546 - acc: 0.3254 - val_loss: 0.0854 - val_acc: 0.3561\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.10850 to 0.08536, saving model to /content/drive/MyDrive/Colab Notebooks/model/Unet_Bakteri_white_background.h5\n",
            "Training: epoch 7 ends at 13:44:07.638542\n",
            "Epoch 9/20\n",
            "20/20 [==============================] - 96s 5s/step - loss: 0.1351 - acc: 0.3513 - val_loss: 0.0822 - val_acc: 0.2344\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.08536 to 0.08218, saving model to /content/drive/MyDrive/Colab Notebooks/model/Unet_Bakteri_white_background.h5\n",
            "Training: epoch 8 ends at 13:45:44.640559\n",
            "Epoch 10/20\n",
            "20/20 [==============================] - 97s 5s/step - loss: 0.1200 - acc: 0.3448 - val_loss: 0.0753 - val_acc: 0.3833\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.08218 to 0.07526, saving model to /content/drive/MyDrive/Colab Notebooks/model/Unet_Bakteri_white_background.h5\n",
            "Training: epoch 9 ends at 13:47:22.927275\n",
            "Epoch 11/20\n",
            "20/20 [==============================] - 96s 5s/step - loss: 0.1075 - acc: 0.3640 - val_loss: 0.0706 - val_acc: 0.3615\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.07526 to 0.07064, saving model to /content/drive/MyDrive/Colab Notebooks/model/Unet_Bakteri_white_background.h5\n",
            "Training: epoch 10 ends at 13:49:00.267427\n",
            "Epoch 12/20\n",
            "20/20 [==============================] - 95s 5s/step - loss: 0.1045 - acc: 0.3627 - val_loss: 0.0714 - val_acc: 0.4005\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.07064\n",
            "Training: epoch 11 ends at 13:50:35.764428\n",
            "Epoch 13/20\n",
            "20/20 [==============================] - 97s 5s/step - loss: 0.1022 - acc: 0.3622 - val_loss: 0.0733 - val_acc: 0.5237\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.07064\n",
            "Training: epoch 12 ends at 13:52:13.631641\n",
            "Epoch 14/20\n",
            "20/20 [==============================] - 98s 5s/step - loss: 0.1025 - acc: 0.3716 - val_loss: 0.0668 - val_acc: 0.3830\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.07064 to 0.06676, saving model to /content/drive/MyDrive/Colab Notebooks/model/Unet_Bakteri_white_background.h5\n",
            "Training: epoch 13 ends at 13:53:52.804741\n",
            "Epoch 15/20\n",
            "20/20 [==============================] - 96s 5s/step - loss: 0.0940 - acc: 0.3500 - val_loss: 0.0615 - val_acc: 0.5051\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.06676 to 0.06147, saving model to /content/drive/MyDrive/Colab Notebooks/model/Unet_Bakteri_white_background.h5\n",
            "Training: epoch 14 ends at 13:55:29.837864\n",
            "Epoch 16/20\n",
            "20/20 [==============================] - 97s 5s/step - loss: 0.0991 - acc: 0.3819 - val_loss: 0.0587 - val_acc: 0.3796\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.06147 to 0.05871, saving model to /content/drive/MyDrive/Colab Notebooks/model/Unet_Bakteri_white_background.h5\n",
            "Training: epoch 15 ends at 13:57:07.780182\n",
            "Epoch 17/20\n",
            "20/20 [==============================] - 97s 5s/step - loss: 0.0934 - acc: 0.3582 - val_loss: 0.0660 - val_acc: 0.5222\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.05871\n",
            "Training: epoch 16 ends at 13:58:45.610258\n",
            "Epoch 18/20\n",
            "20/20 [==============================] - 96s 5s/step - loss: 0.0881 - acc: 0.3707 - val_loss: 0.0698 - val_acc: 0.4384\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.05871\n",
            "Training: epoch 17 ends at 14:00:22.569209\n",
            "Epoch 19/20\n",
            "20/20 [==============================] - 96s 5s/step - loss: 0.0862 - acc: 0.3672 - val_loss: 0.0686 - val_acc: 0.3187\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.05871\n",
            "Training: epoch 18 ends at 14:01:59.681282\n",
            "Epoch 20/20\n",
            "20/20 [==============================] - 97s 5s/step - loss: 0.0881 - acc: 0.3552 - val_loss: 0.0628 - val_acc: 0.3332\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.05871\n",
            "Training: epoch 19 ends at 14:03:37.085191\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Us3WDEcOm8X"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_oeRIJU33AD"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAgS6Tq8SJI6"
      },
      "source": [
        "res_dir = \"/content/drive/MyDrive/Colab Notebooks/Bakteri/hasil_tes/\"\n",
        "\n",
        "X = X_test\n",
        "Y = y_test\n",
        "\n",
        "for a in range(len(X)):\n",
        "  print(a)\n",
        "\n",
        "  x_rand = X[a]\n",
        "  y_rand = x_rand[:-4]+\".jpg\"\n",
        "\n",
        "  x_path = f\"{ImgDir}image/{x_rand}\"\n",
        "  y_path = f\"{ImgDir}mask/{y_rand}\"\n",
        "\n",
        "  x = cv2.imread(x_path)\n",
        "  x = cv2.resize(x, (IMG_WIDTH, IMG_HEIGHT))\n",
        "  y = cv2.imread(y_path)\n",
        "  y = cv2.resize(y, (IMG_WIDTH, IMG_HEIGHT))\n",
        "\n",
        "  x = x / 255.0\n",
        "  y = y / 255.0\n",
        "\n",
        "  p = np.reshape(x, (1, 160, 160, 3))\n",
        "  prediction = model.predict(p)\n",
        "\n",
        "  x_img = f\"{res_dir}{a}_X_input.jpg\"\n",
        "  y_img = f\"{res_dir}{a}_Y_truth.jpg\"\n",
        "  predicted_img = f\"{res_dir}{a}_Y_predicted.jpg\"\n",
        "\n",
        "  cv2.imwrite(x_img, x * 255.)\n",
        "  cv2.imwrite(y_img, y * 255.)\n",
        "  cv2.imwrite(predicted_img, prediction[0] * 255.)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}